version: '3.8'

services:
    # 프로덕션 메인 백엔드
    backend-prod:
        build:
            context: ./server
            dockerfile: Dockerfile
            target: production
        ports:
            - '8000:8000'
        environment:
            - ENV=production
            - FIREBASE_PROJECT_ID=${FIREBASE_PROJECT_ID}
            - LLM_SERVICE_URL=http://llm-service-prod:8002
        env_file:
            - ./server/.env
        depends_on:
            - llm-service-prod
        networks:
            - together-kids-prod-network
        restart: always
        healthcheck:
            test: ['CMD', 'curl', '-f', 'http://localhost:8000/health']
            interval: 30s
            timeout: 10s
            retries: 3
        logging:
            driver: 'json-file'
            options:
                max-size: '10m'
                max-file: '3'

    # 프로덕션 LLM 서비스
    llm-service-prod:
        build:
            context: ./server
            dockerfile: Dockerfile
            target: production
        ports:
            - '8002:8002'
        environment:
            - ENV=production
            - OPENAI_API_KEY=${OPENAI_API_KEY}
            - NAVER_CLIENT_ID=${NAVER_CLIENT_ID}
            - NAVER_CLIENT_SECRET=${NAVER_CLIENT_SECRET}
            - FIREBASE_PROJECT_ID=${FIREBASE_PROJECT_ID}
        env_file:
            - ./server/.env
        volumes:
            - chroma_prod_data:/app/llm_service/chroma_db
        networks:
            - together-kids-prod-network
        restart: always
        command: uvicorn llm_service.main:app --host 0.0.0.0 --port 8002 --workers 2
        healthcheck:
            test: ['CMD', 'curl', '-f', 'http://localhost:8002/health']
            interval: 30s
            timeout: 10s
            retries: 3
        logging:
            driver: 'json-file'
            options:
                max-size: '10m'
                max-file: '3'

    # 프로덕션 프론트엔드 (Nginx)
    frontend-prod:
        build:
            context: ./frontend
            dockerfile: Dockerfile
            target: production
        ports:
            - '80:80'
            - '443:443'
        environment:
            - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL}
            - NEXT_PUBLIC_NAVER_CLIENT_ID=${NEXT_PUBLIC_NAVER_CLIENT_ID}
            - NEXT_PUBLIC_FIREBASE_API_KEY=${NEXT_PUBLIC_FIREBASE_API_KEY}
            - NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN=${NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN}
            - NEXT_PUBLIC_FIREBASE_PROJECT_ID=${NEXT_PUBLIC_FIREBASE_PROJECT_ID}
        env_file:
            - ./frontend/.env.local
        depends_on:
            - backend-prod
            - llm-service-prod
        networks:
            - together-kids-prod-network
        restart: always
        healthcheck:
            test: ['CMD', 'curl', '-f', 'http://localhost:80']
            interval: 30s
            timeout: 10s
            retries: 3
        logging:
            driver: 'json-file'
            options:
                max-size: '10m'
                max-file: '3'

networks:
    together-kids-prod-network:
        driver: bridge

volumes:
    chroma_prod_data:
        driver: local
