from fastapi import APIRouter, Depends, HTTPException, Query
from typing import Optional, List
import httpx
import os
import json
from ..firebase_config import get_firestore_db

from ..schemas import User
from ..dependencies import get_current_user

# Firestore DB ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
def get_db():
    try:
        return get_firestore_db()
    except Exception:
        return None

db = get_db()

router = APIRouter(prefix="/ai", tags=["ai-integration"])

# í†µí•© ì„œë¹„ìŠ¤ URL (Backend + LLM Service í†µí•©)
LLM_SERVICE_URL = os.getenv("LLM_SERVICE_URL", "https://hackathon-integrated-service-529342898795.asia-northeast3.run.app")
LLM_SERVICE_API_KEY = os.getenv("LLM_SERVICE_API_KEY")

def get_user_context(current_user: dict) -> dict:
    uid = current_user.get("uid")
    try:
        user_ref = db.collection("users").document(uid)
        user_doc = user_ref.get()
        user_data = user_doc.to_dict() if user_doc.exists else {}

        
        children_ref = db.collection("users").document(uid).collection("children")
        children_docs = children_ref.get()
        children_info = []
        
        # Firestore ë‚ ì§œ ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        for child in children_docs:
            child_data = child.to_dict()
            if child_data:
                # ë‚ ì§œ ê°ì²´ë“¤ì„ ISO ë¬¸ìì—´ë¡œ ë³€í™˜
                if 'created_at' in child_data and hasattr(child_data['created_at'], 'isoformat'):
                    child_data['created_at'] = child_data['created_at'].isoformat()
                if 'updated_at' in child_data and hasattr(child_data['updated_at'], 'isoformat'):
                    child_data['updated_at'] = child_data['updated_at'].isoformat()
                    
                children_info.append(child_data)

        user_context = {
            "user_id": uid,
            "user_name": user_data.get("user_name", ""),
            "full_name": user_data.get("full_name", ""),
            "apartments": user_data.get("apartments", []),
            "children": children_info
        }
        return user_context
    except Exception as e:
        print(f"ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìµœì†Œí•œì˜ ì •ë³´ë§Œ ë°˜í™˜
        return {"user_id": uid}

@router.post("/chat")
async def chat_with_ai(
    message: str = Query(..., description="ì±„íŒ… ë©”ì‹œì§€"),
    mode: str = Query("auto", description="ì±„íŒ… ëª¨ë“œ"),
    current_user: dict = Depends(get_current_user)
):
   try:
       print(f"=== AI ì±„íŒ… ìš”ì²­ ì‹œì‘: {current_user.get('uid')} ===")
       print(f"ë©”ì‹œì§€: {message}")
       
       user_context = get_user_context(current_user)
       print(f"ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸: {user_context}")

       # í†µí•© ì„œë¹„ìŠ¤ì—ì„œëŠ” ì§ì ‘ LLM ë¼ìš°í„° í•¨ìˆ˜ í˜¸ì¶œ
       try:
           from llm_service.routers.chat import unified_chat_endpoint
           from llm_service.models.chat_models import ChatRequest
           print("âœ… LLM ëª¨ë“ˆ import ì„±ê³µ")
       except ImportError as import_err:
           print(f"âŒ LLM ëª¨ë“ˆ import ì‹¤íŒ¨: {import_err}")
           raise
       
       # ChatRequest ê°ì²´ ìƒì„±
       try:
           chat_request = ChatRequest(
               user_id=current_user.get("uid"),
               message=message,
               conversation_context={},
               user_context=user_context
           )
           print("âœ… ChatRequest ê°ì²´ ìƒì„± ì„±ê³µ")
       except Exception as req_err:
           print(f"âŒ ChatRequest ìƒì„± ì‹¤íŒ¨: {req_err}")
           raise
       
       print(f"ğŸ”„ LLM ë¼ìš°í„° ì§ì ‘ í˜¸ì¶œ ì‹œì‘...")
       result = await unified_chat_endpoint(chat_request)
       print(f"âœ… LLM ë¼ìš°í„° í˜¸ì¶œ ì„±ê³µ")
       
       print(f"LLM ì²˜ë¦¬ ì™„ë£Œ")
       return result
            
   except Exception as e:
       import traceback
       error_details = traceback.format_exc()
       print(f"AI ì±„íŒ… ì˜¤ë¥˜: {str(e)}")
       print(f"ìƒì„¸ ì˜¤ë¥˜: {error_details}")
       raise HTTPException(status_code=500, detail=f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)} | ìƒì„¸: {error_details[:200]}")

@router.post("/chat/ai-only")
async def chat_ai_only(
    message: str = Query(..., description="ì±„íŒ… ë©”ì‹œì§€"),
    current_user: dict = Depends(get_current_user)
):
    """AI ì „ìš© ì±„íŒ…"""
    return await chat_with_ai(message, "ai_only", current_user)


@router.post("/chat/community")
async def chat_community(
    message: str = Query(..., description="ì±„íŒ… ë©”ì‹œì§€"),
    current_user: dict = Depends(get_current_user)
):
    """ì»¤ë®¤ë‹ˆí‹° ê²€ìƒ‰ ì±„íŒ…"""
    return await chat_with_ai(message, "community_only", current_user)


@router.get("/chat/history")
async def get_chat_history(
    limit: int = Query(50, description="ì¡°íšŒí•  ë©”ì‹œì§€ ìˆ˜"),
    current_user: dict = Depends(get_current_user)
):
    """ì±„íŒ… íˆìŠ¤í† ë¦¬ ì¡°íšŒ (LLM ì„œë¹„ìŠ¤ì—ì„œ)"""
    try:
        async with httpx.AsyncClient() as client:
            headers = {}
            if LLM_SERVICE_API_KEY:
                headers["Authorization"] = f"Bearer {LLM_SERVICE_API_KEY}"
            
            response = await client.get(
                f"{LLM_SERVICE_URL}/chat/history",
                params={ "user_id": current_user.get("uid"), "limit": limit },
                headers=headers,
                timeout=10.0
            )
            
            response.raise_for_status()
            return response.json()
    except Exception as e:
        return {"history": [], "message": f"íˆìŠ¤í† ë¦¬ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}"}

@router.delete("/chat/history")
async def clear_chat_history(
    current_user: dict = Depends(get_current_user)
):
    """ì±„íŒ… íˆìŠ¤í† ë¦¬ ì‚­ì œ"""
    try:
        async with httpx.AsyncClient() as client:
            headers = {}
            if LLM_SERVICE_API_KEY:
                headers["Authorization"] = f"Bearer {LLM_SERVICE_API_KEY}"
            
            response = await client.delete(
                f"{LLM_SERVICE_URL}/chat/history",
                params={"user_id": current_user.get("uid")},
                headers=headers,
                timeout=10.0
            )
            
            response.raise_for_status()
            return response.json()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íˆìŠ¤í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨: {e}")

@router.get("/suggestions")
async def get_ai_suggestions(
    context: str = Query("general", description="ì œì•ˆ ì»¨í…ìŠ¤íŠ¸"),
    current_user: dict = Depends(get_current_user)
):
    """AI ì œì•ˆì‚¬í•­ ì¡°íšŒ"""
    user_context = get_user_context(current_user)
    
    suggestions = {
        "general": ["ì˜¤ëŠ˜ ì•„ì´ ì¼ì •ì„ í™•ì¸í•´ë³´ì„¸ìš”", "ìš°ë¦¬ ì•„íŒŒíŠ¸ ì»¤ë®¤ë‹ˆí‹° ì†Œì‹ì„ í™•ì¸í•´ë³´ì„¸ìš”"],
        "schedule": ["ë‹¤ê°€ì˜¤ëŠ” ì˜ˆë°©ì ‘ì¢… ì¼ì •ì´ ìˆë‚˜ìš”?", "ì´ë²ˆ ì£¼ ë†€ì´ ì‹œê°„ì„ ê³„íší•´ë³´ì„¸ìš”"],
        "community": ["ê°™ì€ ë˜ë˜ ì•„ì´ë¥¼ í‚¤ìš°ëŠ” ë¶€ëª¨ë“¤ê³¼ ì†Œí†µí•´ë³´ì„¸ìš”", "ìœ¡ì•„ ìš©í’ˆ ë‚˜ëˆ” ê²Œì‹œê¸€ì„ í™•ì¸í•´ë³´ì„¸ìš”"]
    }
    
    return {
        "context": context,
        "suggestions": suggestions.get(context, suggestions["general"]),
        "user_context": user_context
    }
